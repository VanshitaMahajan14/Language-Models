{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:21:12.799211Z",
     "iopub.status.busy": "2024-09-11T06:21:12.798827Z",
     "iopub.status.idle": "2024-09-11T06:21:12.916867Z",
     "shell.execute_reply": "2024-09-11T06:21:12.915733Z",
     "shell.execute_reply.started": "2024-09-11T06:21:12.799175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Val, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:21:12.919545Z",
     "iopub.status.busy": "2024-09-11T06:21:12.918918Z",
     "iopub.status.idle": "2024-09-11T06:21:31.134684Z",
     "shell.execute_reply": "2024-09-11T06:21:31.133657Z",
     "shell.execute_reply.started": "2024-09-11T06:21:12.919494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokenized train sentences: 41528\n",
      "Number of tokenized validation sentences: 11865\n",
      "Number of tokenized test sentences: 5932\n"
     ]
    }
   ],
   "source": [
    "corpus_path = '/kaggle/input/auguste-maquet/Auguste_Maquet.txt'\n",
    "\n",
    "# Load the entire corpus\n",
    "with open(corpus_path, \"r\") as f:\n",
    "    corpus = f.read()\n",
    "\n",
    "def clean(data):\n",
    "    data = data.lower()\n",
    "    data = re.sub(r'\\n|\\s+', ' ', data)  # replace newline and multiple spaces with single space\n",
    "    data = re.sub(r\"[^a-zA-Z0-9\\s,.!?;:]\", \"\", data) \n",
    "    data = re.sub(r'[’‘]', '\\'', data)  # apostrophes\n",
    "    data = re.sub(r'[“”`\\' ]|[–—-]', ' ', data)  # quotes and dashes\n",
    "    data = data.strip()\n",
    "    return data\n",
    "\n",
    "corpus = clean(corpus)\n",
    "sentences = sent_tokenize(corpus)\n",
    "\n",
    "def add_start_and_end_tokens(sentences):\n",
    "    modified_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        tokenized_sentence = word_tokenize(sentence)\n",
    "        new_sentence = ['<S>'] + tokenized_sentence + ['</S>']\n",
    "        modified_sentences.append(new_sentence)\n",
    "    return modified_sentences\n",
    "\n",
    "sentences = add_start_and_end_tokens(sentences)\n",
    "\n",
    "# Calculate the adjusted split sizes\n",
    "train_size = int(0.7 * len(sentences))\n",
    "val_size = int(0.2 * len(sentences))\n",
    "test_size = int(0.1 * len(sentences))\n",
    "\n",
    "train_sentences = sentences[:train_size]\n",
    "validation_sentences = sentences[train_size:train_size + val_size]\n",
    "test_sentences = sentences[train_size + val_size:train_size + val_size + test_size]\n",
    "\n",
    "print(f\"Number of tokenized train sentences: {len(train_sentences)}\")\n",
    "print(f\"Number of tokenized validation sentences: {len(validation_sentences)}\")\n",
    "print(f\"Number of tokenized test sentences: {len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:21:31.136381Z",
     "iopub.status.busy": "2024-09-11T06:21:31.135997Z",
     "iopub.status.idle": "2024-09-11T06:21:31.326525Z",
     "shell.execute_reply": "2024-09-11T06:21:31.325379Z",
     "shell.execute_reply.started": "2024-09-11T06:21:31.136345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 22266\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(sentences):\n",
    "    all_words = [word for sentence in sentences for word in sentence]\n",
    "    word_counts = Counter(all_words)\n",
    "    vocab = set(word_counts.keys())\n",
    "    return vocab\n",
    "\n",
    "all_sentences = train_sentences\n",
    "vocab = build_vocab(all_sentences)\n",
    "\n",
    "special_tokens = ['<UNK>', '<PAD>', '<S>', '</S>']\n",
    "for token in special_tokens:\n",
    "    vocab.add(token)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:21:31.329159Z",
     "iopub.status.busy": "2024-09-11T06:21:31.328796Z",
     "iopub.status.idle": "2024-09-11T06:22:06.598320Z",
     "shell.execute_reply": "2024-09-11T06:22:06.597321Z",
     "shell.execute_reply.started": "2024-09-11T06:21:31.329124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe embeddings with dimension: 300\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "def load_glove_embeddings(glove_path):\n",
    "    word_embeddings = {}\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_embeddings[word] = vector\n",
    "\n",
    "    special_tokens = ['<UNK>', '<PAD>', '<S>', '</S>']\n",
    "    for token in special_tokens:\n",
    "        if token in ['<S>', '</S>']:\n",
    "              # Random initialization for special tokens\n",
    "            word_embeddings[token] = np.random.rand(embedding_dim).astype('float32')\n",
    "        elif token == '<UNK>':\n",
    "              # Mean of all embeddings in GloVe for <UNK>\n",
    "            all_vectors = np.array(list(word_embeddings.values()))\n",
    "            mean_vector = np.mean(all_vectors, axis=0)\n",
    "            word_embeddings[token] = mean_vector\n",
    "        elif token == '<PAD>':\n",
    "              # Zero initialization for <PAD>\n",
    "            word_embeddings[token] = np.zeros(embedding_dim, dtype='float32')\n",
    "\n",
    "    return word_embeddings\n",
    "\n",
    "glove_path = '/kaggle/input/glove-300/glove.6B.300d.txt'\n",
    "glove_embeddings = load_glove_embeddings(glove_path)\n",
    "\n",
    "embedding_dim = len(glove_embeddings[next(iter(glove_embeddings))])\n",
    "print(f\"Loaded GloVe embeddings with dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:22:06.600146Z",
     "iopub.status.busy": "2024-09-11T06:22:06.599739Z",
     "iopub.status.idle": "2024-09-11T06:22:06.651878Z",
     "shell.execute_reply": "2024-09-11T06:22:06.650819Z",
     "shell.execute_reply.started": "2024-09-11T06:22:06.600107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word2index mapping: [('pan', 0), ('morocco', 1), ('commencing', 2), ('15.', 3), ('sexes', 4), ('efficacious', 5), ('opposed', 6), ('bravoes', 7), ('decrepitude', 8), ('mazarinimpossible', 9)]\n",
      "Sample index2word mapping: [(0, 'pan'), (1, 'morocco'), (2, 'commencing'), (3, '15.'), (4, 'sexes'), (5, 'efficacious'), (6, 'opposed'), (7, 'bravoes'), (8, 'decrepitude'), (9, 'mazarinimpossible')]\n"
     ]
    }
   ],
   "source": [
    "def build_mappings(vocab, glove_embeddings):\n",
    "    word2index = {word: idx for idx, word in enumerate(vocab)}\n",
    "    index2word = {idx: word for word, idx in word2index.items()}\n",
    "\n",
    "    return word2index, index2word\n",
    "\n",
    "word2index, index2word = build_mappings(vocab, glove_embeddings)\n",
    "\n",
    "print(f\"Sample word2index mapping: {list(word2index.items())[:10]}\")\n",
    "print(f\"Sample index2word mapping: {list(index2word.items())[:10]}\")\n",
    "\n",
    "# Check if all words have corresponding embeddings\n",
    "count = 0;\n",
    "for word in word2index.keys():\n",
    "    if word not in glove_embeddings:\n",
    "        count = count + 1\n",
    "        # print(f\"Warning: GloVe embedding missing for {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:22:06.653731Z",
     "iopub.status.busy": "2024-09-11T06:22:06.653278Z",
     "iopub.status.idle": "2024-09-11T06:22:06.762949Z",
     "shell.execute_reply": "2024-09-11T06:22:06.761756Z",
     "shell.execute_reply.started": "2024-09-11T06:22:06.653662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings matrix: (22266, 300)\n"
     ]
    }
   ],
   "source": [
    "len(vocab), len(word2index), len(glove_embeddings), count\n",
    "\n",
    "embedding_dim = 300\n",
    "vocab_size = len(word2index)\n",
    "embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for idx, word in index2word.items():\n",
    "    if word in glove_embeddings:\n",
    "        embeddings_matrix[idx] = glove_embeddings[word]\n",
    "    else:\n",
    "        unknown_embeds = glove_embeddings['<UNK>']\n",
    "        embeddings_matrix[idx] = unknown_embeds\n",
    "\n",
    "# Check the shape of the embeddings matrix\n",
    "print(f\"Shape of embeddings matrix: {embeddings_matrix.shape}\")\n",
    "embeddings_matrix = torch.tensor(embeddings_matrix, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:22:06.765003Z",
     "iopub.status.busy": "2024-09-11T06:22:06.764599Z",
     "iopub.status.idle": "2024-09-11T06:22:06.772032Z",
     "shell.execute_reply": "2024-09-11T06:22:06.770897Z",
     "shell.execute_reply.started": "2024-09-11T06:22:06.764959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22266, 22266, 400004, 4628)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab), len(word2index), len(glove_embeddings), count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:22:06.774334Z",
     "iopub.status.busy": "2024-09-11T06:22:06.773844Z",
     "iopub.status.idle": "2024-09-11T06:22:07.812532Z",
     "shell.execute_reply": "2024-09-11T06:22:07.811410Z",
     "shell.execute_reply.started": "2024-09-11T06:22:06.774288Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_index(word, word2index):\n",
    "    \"\"\"Returns the index for the word or a special token index if not found.\"\"\"\n",
    "    return word2index.get(word, word2index.get('<UNK>'))\n",
    "\n",
    "def create_context_label_dataset(sentences, index2word):\n",
    "    contexts = []\n",
    "    labels = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_indices = [get_index(word, word2index) for word in sentence]\n",
    "\n",
    "        # Create context (all words except the last) and label (all words except the first)\n",
    "        context = sentence_indices[:-1]\n",
    "        label = sentence_indices[1:]\n",
    "\n",
    "        contexts.append(context)\n",
    "        labels.append(label)\n",
    "\n",
    "    return contexts, labels\n",
    "\n",
    "\n",
    "train_contexts, train_labels = create_context_label_dataset(train_sentences, word2index)\n",
    "val_contexts, val_labels = create_context_label_dataset(validation_sentences, word2index)\n",
    "test_contexts, test_labels = create_context_label_dataset(test_sentences, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:22:07.814907Z",
     "iopub.status.busy": "2024-09-11T06:22:07.814084Z",
     "iopub.status.idle": "2024-09-11T06:22:07.854098Z",
     "shell.execute_reply": "2024-09-11T06:22:07.853184Z",
     "shell.execute_reply.started": "2024-09-11T06:22:07.814861Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, contexts, labels):\n",
    "        self.contexts = contexts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.contexts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.contexts[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "train_dataset = TextDataset(train_contexts, train_labels)\n",
    "validation_dataset = TextDataset(val_contexts, val_labels)\n",
    "test_dataset = TextDataset(test_contexts, test_labels)\n",
    "\n",
    "# collate function for padding\n",
    "def collate_fn(batch):\n",
    "    contexts, labels = zip(*batch)\n",
    "    # Pad sequences with '<PAD>' to make all sentences in the batch the same length\n",
    "    contexts_padded = pad_sequence(contexts, batch_first=True, padding_value=word2index['<PAD>'])\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=word2index['<PAD>'])\n",
    "    return contexts_padded, labels_padded\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:22:07.859489Z",
     "iopub.status.busy": "2024-09-11T06:22:07.859148Z",
     "iopub.status.idle": "2024-09-11T06:22:07.868151Z",
     "shell.execute_reply": "2024-09-11T06:22:07.867031Z",
     "shell.execute_reply.started": "2024-09-11T06:22:07.859453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:22:07.869743Z",
     "iopub.status.busy": "2024-09-11T06:22:07.869353Z",
     "iopub.status.idle": "2024-09-11T06:22:07.877020Z",
     "shell.execute_reply": "2024-09-11T06:22:07.875887Z",
     "shell.execute_reply.started": "2024-09-11T06:22:07.869702Z"
    }
   },
   "outputs": [],
   "source": [
    "def pos_encoding(num_tokens, n_dim):\n",
    "    pos_enc = np.zeros((num_tokens, n_dim))\n",
    "    positions = np.arange(num_tokens)[:, np.newaxis]\n",
    "    div_term = np.exp(np.arange(0, n_dim, 2) * -(np.log(10000.0) / n_dim))\n",
    "    pos_enc[:, 0::2] = np.sin(positions * div_term)\n",
    "    pos_enc[:, 1::2] = np.cos(positions * div_term)\n",
    "    return torch.tensor(pos_enc, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:22:07.878885Z",
     "iopub.status.busy": "2024-09-11T06:22:07.878479Z",
     "iopub.status.idle": "2024-09-11T06:22:07.998549Z",
     "shell.execute_reply": "2024-09-11T06:22:07.997625Z",
     "shell.execute_reply.started": "2024-09-11T06:22:07.878841Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerDecoderModel(nn.Module):\n",
    "    def __init__(self, embedding, vocab_size, embedding_dim, hidden_dim, num_layers,  num_heads, dropout = 0.1):\n",
    "        super(TransformerDecoderModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding, freeze=True)\n",
    "        self.positional_encoding = pos_encoding(1000, embedding_dim).to(device)\n",
    "        \n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embedding_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        \n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer=decoder_layer,num_layers=num_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "    \n",
    "    def forward(self, tgt, tgt_mask=None):\n",
    "        tgt = self.embedding(tgt) + self.positional_encoding[:tgt.size(1)]\n",
    "        tgt = self.layer_norm(tgt)\n",
    "        output = self.transformer_decoder(tgt, memory=tgt, tgt_mask=tgt_mask)  # Use tgt as memory\n",
    "        output = self.fc_out(self.dropout(output))\n",
    "        return output\n",
    "    \n",
    "# Model params\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "num_heads = 10\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "pad_idx = word2index['<PAD>']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = TransformerDecoderModel(embeddings_matrix, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads,  dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=0, factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:23:51.475884Z",
     "iopub.status.busy": "2024-09-11T06:23:51.475135Z",
     "iopub.status.idle": "2024-09-11T06:23:51.489208Z",
     "shell.execute_reply": "2024-09-11T06:23:51.488018Z",
     "shell.execute_reply.started": "2024-09-11T06:23:51.475843Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, patience):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        for batch_idx, (contexts, labels) in enumerate(train_loader):\n",
    "            contexts, labels = contexts.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass through the model\n",
    "            output = model(contexts)\n",
    "\n",
    "            # Reshape output and labels for CrossEntropyLoss\n",
    "            loss = criterion(output.view(-1, output.size(-1)), labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        hidden = None\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation for validation\n",
    "            for batch_idx, (contexts, labels) in enumerate(val_loader):\n",
    "                contexts, labels = contexts.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass through the model\n",
    "                output = model(contexts)\n",
    "\n",
    "                # Compute the validation loss\n",
    "                loss = criterion(output.view(-1, output.size(-1)), labels.view(-1))\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'Transformer_model.pth') \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:23:51.623332Z",
     "iopub.status.busy": "2024-09-11T06:23:51.622539Z",
     "iopub.status.idle": "2024-09-11T06:35:57.158629Z",
     "shell.execute_reply": "2024-09-11T06:35:57.157557Z",
     "shell.execute_reply.started": "2024-09-11T06:23:51.623294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 5.5716\n",
      "Validation Loss: 5.0361\n",
      "Epoch 2/10\n",
      "Train Loss: 4.8901\n",
      "Validation Loss: 4.9144\n",
      "Epoch 3/10\n",
      "Train Loss: 4.7245\n",
      "Validation Loss: 4.8812\n",
      "Epoch 4/10\n",
      "Train Loss: 4.6172\n",
      "Validation Loss: 4.8786\n",
      "Epoch 5/10\n",
      "Train Loss: 4.5339\n",
      "Validation Loss: 4.8850\n",
      "Epoch 6/10\n",
      "Train Loss: 4.3493\n",
      "Validation Loss: 4.8646\n",
      "Epoch 7/10\n",
      "Train Loss: 4.3128\n",
      "Validation Loss: 4.8733\n",
      "Epoch 8/10\n",
      "Train Loss: 4.2790\n",
      "Validation Loss: 4.8743\n",
      "Epoch 9/10\n",
      "Train Loss: 4.2736\n",
      "Validation Loss: 4.8719\n",
      "Early stopping triggered after 9 epochs.\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, validation_loader, criterion, optimizer, scheduler, device, num_epochs = 10, patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:36:07.306426Z",
     "iopub.status.busy": "2024-09-11T06:36:07.305453Z",
     "iopub.status.idle": "2024-09-11T06:36:07.313772Z",
     "shell.execute_reply": "2024-09-11T06:36:07.312863Z",
     "shell.execute_reply.started": "2024-09-11T06:36:07.306378Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_test_metrics(model, test_loader, device, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        for batch_idx, (contexts, labels) in enumerate(test_loader):\n",
    "            contexts, labels = contexts.to(device), labels.to(device)\n",
    "\n",
    "            batch_size = contexts.size(0)\n",
    "            output = model(contexts)\n",
    "            \n",
    "            loss = criterion(output.view(-1, output.size(-1)), labels.view(-1))\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    perplexity = math.exp(avg_test_loss)\n",
    "\n",
    "    return avg_test_loss, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:36:09.428116Z",
     "iopub.status.busy": "2024-09-11T06:36:09.427646Z",
     "iopub.status.idle": "2024-09-11T06:36:09.433414Z",
     "shell.execute_reply": "2024-09-11T06:36:09.432318Z",
     "shell.execute_reply.started": "2024-09-11T06:36:09.428076Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:36:38.086632Z",
     "iopub.status.busy": "2024-09-11T06:36:38.086245Z",
     "iopub.status.idle": "2024-09-11T06:36:38.181822Z",
     "shell.execute_reply": "2024-09-11T06:36:38.180810Z",
     "shell.execute_reply.started": "2024-09-11T06:36:38.086595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 2021101102-LM3-Transformer.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model,\"2021101102-LM3-Transformer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:36:44.361712Z",
     "iopub.status.busy": "2024-09-11T06:36:44.361003Z",
     "iopub.status.idle": "2024-09-11T06:37:17.206931Z",
     "shell.execute_reply": "2024-09-11T06:37:17.205963Z",
     "shell.execute_reply.started": "2024-09-11T06:36:44.361657Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss, train_perplexity =  calculate_test_metrics(model, train_loader, device, criterion)\n",
    "val_loss, val_perplexity = calculate_test_metrics(model, validation_loader, device, criterion)\n",
    "test_loss, test_perplexity = calculate_test_metrics(model, test_loader, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:38:13.875469Z",
     "iopub.status.busy": "2024-09-11T06:38:13.875052Z",
     "iopub.status.idle": "2024-09-11T06:38:13.881091Z",
     "shell.execute_reply": "2024-09-11T06:38:13.880021Z",
     "shell.execute_reply.started": "2024-09-11T06:38:13.875431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.2069\n",
      "Train Perplexity: 67.1503\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Loss: {train_loss:.4f}\")\n",
    "print(f\"Train Perplexity: {train_perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:38:15.489177Z",
     "iopub.status.busy": "2024-09-11T06:38:15.487987Z",
     "iopub.status.idle": "2024-09-11T06:38:15.494329Z",
     "shell.execute_reply": "2024-09-11T06:38:15.493366Z",
     "shell.execute_reply.started": "2024-09-11T06:38:15.489135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.8729\n",
      "Val Perplexity: 130.7005\n"
     ]
    }
   ],
   "source": [
    "print(f\"Val Loss: {val_loss:.4f}\")\n",
    "print(f\"Val Perplexity: {val_perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:38:17.207874Z",
     "iopub.status.busy": "2024-09-11T06:38:17.207106Z",
     "iopub.status.idle": "2024-09-11T06:38:17.212705Z",
     "shell.execute_reply": "2024-09-11T06:38:17.211742Z",
     "shell.execute_reply.started": "2024-09-11T06:38:17.207834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.8716\n",
      "Test Perplexity: 130.5274\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving perplexities to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:47:07.120212Z",
     "iopub.status.busy": "2024-09-11T06:47:07.119792Z",
     "iopub.status.idle": "2024-09-11T06:47:07.130563Z",
     "shell.execute_reply": "2024-09-11T06:47:07.129360Z",
     "shell.execute_reply.started": "2024-09-11T06:47:07.120170Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_perplexities(model, test_loader, file_name):\n",
    "    \n",
    "    model.eval()  \n",
    "    batch_perplexities = []\n",
    "    total_test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        for batch_idx, (contexts, labels) in enumerate(test_loader):\n",
    "            contexts, labels = contexts.to(device), labels.to(device)\n",
    "            \n",
    "            output = model(contexts)\n",
    "\n",
    "            loss = criterion(output.view(-1, output.size(-1)), labels.view(-1))\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            batch_perplexity = math.exp(loss.item())\n",
    "            batch_perplexities.append(batch_perplexity)\n",
    "\n",
    "            # Write to file (append mode)\n",
    "            with open(file_name, 'a') as f:\n",
    "                f.write(f'Batch {batch_idx + 1}: {batch_perplexity:.4f}\\n')\n",
    "\n",
    "    # Compute the average test loss and perplexity\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    avg_perplexity = math.exp(avg_test_loss)\n",
    "    \n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(f'Average Perplexity: {avg_perplexity:.4f}\\n')\n",
    "\n",
    "    # Print average perplexity\n",
    "    print(f'Average Perplexity: {avg_perplexity:.4f}')\n",
    "\n",
    "    return avg_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T06:47:09.971501Z",
     "iopub.status.busy": "2024-09-11T06:47:09.971045Z",
     "iopub.status.idle": "2024-09-11T06:50:04.924185Z",
     "shell.execute_reply": "2024-09-11T06:50:04.923177Z",
     "shell.execute_reply.started": "2024-09-11T06:47:09.971460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Perplexity: 68.3511\n",
      "Average Perplexity: 118.2290\n",
      "Average Perplexity: 117.8677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117.86770778655399"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"2021101102-LM3-train-perplexity.txt\"\n",
    "val_path = \"2021101102-LM3-val-perplexity.txt\"\n",
    "test_path = \"2021101102_LM3-test-perplexity.txt\"\n",
    "\n",
    "# Createa loaders with size 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "save_perplexities(model, train_loader, train_path)\n",
    "save_perplexities(model, validation_loader, val_path)\n",
    "save_perplexities(model, test_loader, test_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5670551,
     "sourceId": 9354117,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5670709,
     "sourceId": 9354347,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
